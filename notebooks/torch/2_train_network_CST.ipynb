{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e9506c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# ↓ required for docker to avoid permission errors with .cache dir\n",
    "torch.hub.set_dir(\"cache\")  \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "from torchvision.transforms import GaussianBlur, ColorJitter, Compose\n",
    "\n",
    "from cp_toolbox.deep_learning.torch.generators import SegmentationGenerator\n",
    "from cp_toolbox.utils import utils\n",
    "\n",
    "from cst.torch.cst_model import train_cst\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766d3560",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55a8a896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tiles: 116\n",
      "Train: 92 - Validation: 23\n"
     ]
    }
   ],
   "source": [
    "# dtaset parameters\n",
    "input_path = \"/home/schroederubuntu/projects/cp_toolbox_data/epithelium_segmentation/v1/X\"\n",
    "target_path = \"/home/schroederubuntu/projects/cp_toolbox_data/epithelium_segmentation/v1/y\"\n",
    "\n",
    "# training parameters\n",
    "epochs = 10\n",
    "batch_size = 2\n",
    "img_size = (512, 512)\n",
    "\n",
    "# distortion parameters\n",
    "brightness = (0.65, 1.35)\n",
    "contrast = (0.8, 1.2)\n",
    "saturation = (0.8, 1.2)\n",
    "hue = (-0.1, 0.1)  #  -0.5 <= min <= max <= 0.5\n",
    "blur_kernel = 5.\n",
    "blur_sigma = 2.\n",
    "\n",
    "\n",
    "tile_paths = utils.list_file_paths(input_path + \"/2\", [\".png\"])\n",
    "tile_paths2 = random.sample(\n",
    "    utils.list_file_paths(input_path + \"/1\", [\".png\"]), 0)\n",
    "tile_paths = tile_paths + tile_paths2\n",
    "\n",
    "### filtering for p16, cd3 or cd8 or whatever\n",
    "stain = \"p16\"\n",
    "# tile_paths = [i for i in tile_paths if stain in i]  # to use all, just comment here\n",
    "\n",
    "train_tile_paths, \\\n",
    "val_tile_paths, _ = utils.train_val_test_split(\n",
    "    tile_paths, proportion_train=0.8, proportion_val=0.2)\n",
    "\n",
    "\n",
    "print(\"Number of tiles: \" + str(len(tile_paths)))\n",
    "print(\"Train: {} - Validation: {}\".format(\n",
    "    len(train_tile_paths), len(val_tile_paths)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e9cd625",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" image data generators / loaders \"\"\"\n",
    "train_dataset = SegmentationGenerator(\n",
    "    batch_size=batch_size,\n",
    "    img_size=img_size,\n",
    "    image_paths=train_tile_paths,\n",
    "    input_path=input_path,\n",
    "    target_path=target_path,\n",
    "    shuffle=True,\n",
    "    rotate=True\n",
    "    \n",
    ")\n",
    " # drop_last avoids risk of last batch being n=1, which makes training loop fail\n",
    "train_loader = train_dataset.data_loader(drop_last=True) \n",
    "\n",
    "val_dataset = SegmentationGenerator(\n",
    "#     batch_size=batch_size,\n",
    "    batch_size=1,\n",
    "    img_size=img_size,\n",
    "    image_paths=val_tile_paths,\n",
    "    input_path=input_path,\n",
    "    target_path=target_path,\n",
    "    shuffle=False,\n",
    "    rotate=True\n",
    "    \n",
    ")\n",
    " # drop_last avoids risk of last batch being n=1, which makes training loop fail\n",
    "val_loader = val_dataset.data_loader(drop_last=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9af599fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" distortion layer \"\"\"\n",
    "dist_layer = Compose([\n",
    "    ColorJitter(brightness=brightness, contrast=contrast, \n",
    "                saturation=saturation, hue=hue), \n",
    "    GaussianBlur(blur_kernel, blur_sigma)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47d3517b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in cache/pytorch_vision_v0.10.0\n"
     ]
    }
   ],
   "source": [
    "\"\"\" load model \"\"\"\n",
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'deeplabv3_resnet50', \n",
    "                       weights=None, num_classes=1)\n",
    "# ↓ add sigmoid layer in classifier block\n",
    "model.classifier.add_module(\"sigmoid\", nn.Sigmoid())  \n",
    "\n",
    "\"\"\" optimizer \"\"\"\n",
    "opt = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d57dc8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1abeedb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                              | 0/46 [00:00<?, ?it/s]/home/schroederubuntu/anaconda3/envs/cp_toolbox_test/lib/python3.11/site-packages/torch/nn/functional.py:2943: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  warnings.warn(\n",
      "Epoch 0 train - batch 15/46 - cst_loss: 0.716 - l0: 0.693 - lstab: 0.006:  33%|████████▊                  | 15/46 [00:06<00:13,  2.36it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_cst\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdist_layer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdist_layer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_save_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtesting\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_base_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnew_model_test\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     12\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/cp_toolbox_test/lib/python3.11/site-packages/cst/torch/cst_model.py:78\u001b[0m, in \u001b[0;36mtrain_cst\u001b[0;34m(model, train_loader, device, optimizer, dist_layer, val_loader, alpha, base_loss, s_loss, epochs, model_save_path, model_base_name)\u001b[0m\n\u001b[1;32m     75\u001b[0m l_stab \u001b[38;5;241m=\u001b[39m s_loss(torch\u001b[38;5;241m.\u001b[39mlog(torch\u001b[38;5;241m.\u001b[39mclip(outputs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1e-7\u001b[39m, \u001b[38;5;241m0.\u001b[39m, \u001b[38;5;241m1.\u001b[39m)),\n\u001b[1;32m     76\u001b[0m                 torch\u001b[38;5;241m.\u001b[39mclip(dist_outputs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1e-7\u001b[39m, \u001b[38;5;241m0.\u001b[39m, \u001b[38;5;241m1.\u001b[39m),)\n\u001b[1;32m     77\u001b[0m cst_loss \u001b[38;5;241m=\u001b[39m loss_fn(outputs, dist_outputs, labels)\n\u001b[0;32m---> 78\u001b[0m \u001b[43mcst_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     79\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m## print statistics\u001b[39;00m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;66;03m# moving average of 10 batches is shown for less jumpy results\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/cp_toolbox_test/lib/python3.11/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/cp_toolbox_test/lib/python3.11/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_cst(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    device=device,\n",
    "    optimizer=opt,\n",
    "    dist_layer=dist_layer,\n",
    "    val_loader=val_loader,\n",
    "    alpha=2,\n",
    "    epochs=epochs,\n",
    "    model_save_path = \"testing\",\n",
    "    model_base_name= \"new_model_test\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9616f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cp_toolbox_test",
   "language": "python",
   "name": "cp_toolbox_test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
