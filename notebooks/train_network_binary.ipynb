{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab26068e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "# sys.path.append(\"..\")\n",
    "# from cst_model import CSTModel\n",
    "# import distortion_layers as ly\n",
    "# import base_models as bm\n",
    "# import callbacks as cb\n",
    "\n",
    "\n",
    "sys.path.append(\"/main_dir/felipe/projects/processor_apps/pkgs/CST\")\n",
    "from cst.cst_model import CSTModel\n",
    "from cst import distortion_layers as ly\n",
    "from cst import base_models as bm\n",
    "from cst import callbacks as cb\n",
    "\n",
    "\n",
    "# tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "898dbdbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/main_dir/felipe/projects/CST/notebooks'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8323eb6c",
   "metadata": {},
   "source": [
    "### Parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63768923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_path = \"../data\"\n",
    "# train_path = \"/main_dir/felipe/projects/cp_toolbox_data/artifacts_project/training_data/v4\"\n",
    "train_path = \"/main_dir/felipe/projects/epi_seg/src/data/train/split/p16_S360_XR\"\n",
    "\n",
    "save_images = False  # utility class method to store the images and distorted images if True. \n",
    "                    # to make sure images are being properly created\n",
    "\n",
    "tile_size = 128\n",
    "batch_size = 32\n",
    "channels = 3\n",
    "# n_st_components = 2\n",
    "alpha = 0\n",
    "epochs = 10\n",
    "class_mode = \"binary\"\n",
    "\n",
    "validation_split = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb51f97",
   "metadata": {},
   "source": [
    "### Create distortion layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ad8c7bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-01 16:05:24.632722: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-01 16:05:24.636455: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-01 16:05:24.636546: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-01 16:05:24.636967: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-01 16:05:24.637548: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-01 16:05:24.637627: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-01 16:05:24.637674: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-01 16:05:24.918838: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-01 16:05:24.918944: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-01 16:05:24.918997: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-01 16:05:24.919055: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6122 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "dcs = {\n",
    "    \"contrast\": {\"factor\": [0.2, 0.2]},\n",
    "    \"color\": {\"factor\": [20,0,20]},\n",
    "    \"blur\": {\"filter_shape\": 2, \"sigma\": 5.},  # kernel size is 'filter_shape * 2 + 1'\n",
    "    \"brightness\": {\"lower\": .85, \"upper\":1.15}\n",
    "}\n",
    "\n",
    "layers = [\n",
    "    ly.RandomColorByChannel(**dcs[\"color\"]), \n",
    "    tf.keras.layers.RandomContrast(**dcs[\"contrast\"]),\n",
    "    ly.RandomBrightness(**dcs[\"brightness\"]),\n",
    "    ly.RandomGaussianBlur(**dcs[\"blur\"]),\n",
    "    ly.BlueRedChannelSwapLayer(),\n",
    "]\n",
    "\n",
    "\n",
    "# dist_layer = [AdjSaturation(10),\n",
    "#               tf.keras.layers.Lambda(lambda x: x * 0. + 55)]\n",
    "\n",
    "dist_layer = layers\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52430c99",
   "metadata": {},
   "source": [
    "### Load images and assign parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62577f8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 41770 images belonging to 2 classes.\n",
      "Found 10442 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "gen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    validation_split = validation_split\n",
    ")\n",
    "\n",
    "t_flow = gen.flow_from_directory(\n",
    "    directory=train_path,\n",
    "    target_size=(tile_size,tile_size),\n",
    "    color_mode='rgb',  # rgb for color\n",
    "    batch_size=batch_size,\n",
    "    class_mode=class_mode,  # 'sparse' for multiclass, 'binary' for binary \n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "v_flow = gen.flow_from_directory(\n",
    "    directory=train_path,\n",
    "    target_size=(tile_size,tile_size),\n",
    "    color_mode=\"rgb\",  # rgb for color\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    class_mode=class_mode,  # 'sparse' for multiclass, 'binary' for binary\n",
    "    subset='validation'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aed8b4b",
   "metadata": {},
   "source": [
    "### Load and compile network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0e67ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if class_mode == \"binary\":\n",
    "    metrics = [\n",
    "        tf.keras.metrics.BinaryCrossentropy(name=\"bce\"),  # BinaryCrossentropy for binary\n",
    "        tf.keras.metrics.BinaryAccuracy(name=\"acc\")\n",
    "    ]\n",
    "    base_loss = tf.keras.losses.binary_crossentropy\n",
    "    final_layer_node = 1\n",
    "    binary = True\n",
    "    \n",
    "elif class_mode == \"sparse\":\n",
    "    metrics = [\n",
    "        tf.keras.metrics.SparseCategoricalCrossentropy(name=\"sce\"), \n",
    "        tf.keras.metrics.SparseCategoricalAccuracy(name=\"acc\")\n",
    "    ]\n",
    "    base_loss = tf.keras.losses.sparse_categorical_crossentropy\n",
    "    final_layer_node = t_flow.num_classes\n",
    "    binary = False\n",
    "\n",
    "elif class_mode == \"categorical\":\n",
    "    metrics = [\n",
    "        tf.keras.metrics.CategoricalCrossentropy(name=\"cce\"),\n",
    "        tf.keras.metrics.CategoricalAccuracy(name=\"acc\")\n",
    "    ]\n",
    "    base_loss = tf.keras.losses.categorical_crossentropy\n",
    "    final_layer_node = t_flow.num_classes\n",
    "    binary = False\n",
    "    \n",
    "else:\n",
    "    print(\"no class mode provided\")\n",
    "    \n",
    "    \n",
    "base_model = bm.create_thesis_model(tile_size=tile_size, channels=3, final_layer_node=final_layer_node)\n",
    "i = tf.keras.Input(shape=(tile_size, tile_size, channels))\n",
    "x_i = base_model(i)\n",
    "cst_model = CSTModel(inputs=i, outputs=x_i, alpha=alpha, \n",
    "                     dist_layers=dist_layer, binary=binary, save_images=save_images)\n",
    "\n",
    "\n",
    "cst_model.compile(\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3, amsgrad=True),\n",
    "    loss = base_loss,\n",
    "    metrics = metrics \n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546e1c22",
   "metadata": {},
   "source": [
    "### Train network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d20f0ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-01 16:05:27.991396: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-08-01 16:05:28.307232: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "tf.Tensor(0.6862759, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0012051621, shape=(), dtype=float32)\n",
      "tf.Tensor(0.12270687, shape=(), dtype=float32)\n",
      "   1/1306 [..............................] - ETA: 1:15:49 - loss_0: 0.6863 - cst_metric: 0.6863 - bce_: 0.6863 - acc_: 0.5625 - bce_0: 0.6862 - acc_0: 0.5938 - bce_1: 0.7080 - acc_1: 0.5625 - bce_2: 0.6608 - acc_2: 0.6875 - bce_3: 0.6821 - acc_3: 0.5000 - bce_4: 0.7468 - acc_4: 0.5000\n",
      "\n",
      "tf.Tensor(1.3703686, shape=(), dtype=float32)\n",
      "tf.Tensor(0.07268228, shape=(), dtype=float32)\n",
      "tf.Tensor(0.10081835, shape=(), dtype=float32)\n",
      "   2/1306 [..............................] - ETA: 11:49 - loss_0: 0.8573 - cst_metric: 0.7723 - bce_: 0.7718 - acc_: 0.5703 - bce_0: 0.7897 - acc_0: 0.5977 - bce_1: 0.7916 - acc_1: 0.5703 - bce_2: 0.7532 - acc_2: 0.6797 - bce_3: 0.7974 - acc_3: 0.5156 - bce_4: 0.8469 - acc_4: 0.5156  \n",
      "\n",
      "tf.Tensor(1.6346352, shape=(), dtype=float32)\n",
      "tf.Tensor(0.15120378, shape=(), dtype=float32)\n",
      "tf.Tensor(0.32157925, shape=(), dtype=float32)\n",
      "   3/1306 [..............................] - ETA: 11:50 - loss_0: 0.9817 - cst_metric: 0.8430 - bce_: 0.8417 - acc_: 0.5689 - bce_0: 0.8699 - acc_0: 0.5958 - bce_1: 0.8609 - acc_1: 0.5677 - bce_2: 0.8226 - acc_2: 0.6684 - bce_3: 0.8849 - acc_3: 0.5185 - bce_4: 0.9117 - acc_4: 0.5208\n",
      "\n",
      "tf.Tensor(0.7659149, shape=(), dtype=float32)\n",
      "tf.Tensor(0.12390504, shape=(), dtype=float32)\n",
      "tf.Tensor(0.22630835, shape=(), dtype=float32)\n",
      "   4/1306 [..............................] - ETA: 11:51 - loss_0: 1.0148 - cst_metric: 0.8866 - bce_: 0.8850 - acc_: 0.5674 - bce_0: 0.9177 - acc_0: 0.5954 - bce_1: 0.9036 - acc_1: 0.5654 - bce_2: 0.8649 - acc_2: 0.6590 - bce_3: 0.9390 - acc_3: 0.5184 - bce_4: 0.9488 - acc_4: 0.5244\n",
      "\n",
      "tf.Tensor(0.576432, shape=(), dtype=float32)\n",
      "tf.Tensor(0.04012214, shape=(), dtype=float32)\n",
      "tf.Tensor(0.05120034, shape=(), dtype=float32)\n",
      "   5/1306 [..............................] - ETA: 11:56 - loss_0: 1.0132 - cst_metric: 0.9123 - bce_: 0.9107 - acc_: 0.5686 - bce_0: 0.9456 - acc_0: 0.5969 - bce_1: 0.9286 - acc_1: 0.5660 - bce_2: 0.8897 - acc_2: 0.6537 - bce_3: 0.9714 - acc_3: 0.5194 - bce_4: 0.9692 - acc_4: 0.5282\n",
      "\n",
      "tf.Tensor(0.62907094, shape=(), dtype=float32)\n",
      "tf.Tensor(0.022438964, shape=(), dtype=float32)\n",
      "tf.Tensor(0.010736055, shape=(), dtype=float32)\n",
      "   6/1306 [..............................] - ETA: 12:13 - loss_0: 1.0016 - cst_metric: 0.9274 - bce_: 0.9258 - acc_: 0.5703 - bce_0: 0.9618 - acc_0: 0.5989 - bce_1: 0.9432 - acc_1: 0.5673 - bce_2: 0.9043 - acc_2: 0.6499 - bce_3: 0.9909 - acc_3: 0.5204 - bce_4: 0.9799 - acc_4: 0.5316\n",
      "\n",
      "tf.Tensor(0.63195884, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0057628066, shape=(), dtype=float32)\n",
      "tf.Tensor(0.036143385, shape=(), dtype=float32)\n",
      "   7/1306 [..............................] - ETA: 12:08 - loss_0: 0.9870 - cst_metric: 0.9360 - bce_: 0.9346 - acc_: 0.5717 - bce_0: 0.9709 - acc_0: 0.6002 - bce_1: 0.9514 - acc_1: 0.5684 - bce_2: 0.9127 - acc_2: 0.6466 - bce_3: 1.0024 - acc_3: 0.5212 - bce_4: 0.9849 - acc_4: 0.5344\n",
      "\n",
      "tf.Tensor(0.6776755, shape=(), dtype=float32)\n",
      "tf.Tensor(0.23690082, shape=(), dtype=float32)\n",
      "tf.Tensor(0.19835748, shape=(), dtype=float32)\n",
      "   8/1306 [..............................] - ETA: 12:03 - loss_0: 0.9726 - cst_metric: 0.9405 - bce_: 0.9393 - acc_: 0.5726 - bce_0: 0.9757 - acc_0: 0.6010 - bce_1: 0.9557 - acc_1: 0.5692 - bce_2: 0.9174 - acc_2: 0.6435 - bce_3: 1.0089 - acc_3: 0.5217 - bce_4: 0.9865 - acc_4: 0.5365\n",
      "\n",
      "tf.Tensor(0.5356816, shape=(), dtype=float32)\n",
      "tf.Tensor(0.19068989, shape=(), dtype=float32)\n",
      "tf.Tensor(0.24221629, shape=(), dtype=float32)\n",
      "   9/1306 [..............................] - ETA: 12:01 - loss_0: 0.9572 - cst_metric: 0.9424 - bce_: 0.9413 - acc_: 0.5734 - bce_0: 0.9775 - acc_0: 0.6018 - bce_1: 0.9572 - acc_1: 0.5698 - bce_2: 0.9193 - acc_2: 0.6410 - bce_3: 1.0120 - acc_3: 0.5223 - bce_4: 0.9858 - acc_4: 0.5385\n",
      "\n",
      "tf.Tensor(1.1905941, shape=(), dtype=float32)\n",
      "tf.Tensor(0.2963696, shape=(), dtype=float32)\n",
      "tf.Tensor(0.36132467, shape=(), dtype=float32)\n",
      "  10/1306 [..............................] - ETA: 11:58 - loss_0: 0.9485 - cst_metric: 0.9429 - bce_: 0.9420 - acc_: 0.5744 - bce_0: 0.9773 - acc_0: 0.6025 - bce_1: 0.9574 - acc_1: 0.5706 - bce_2: 0.9204 - acc_2: 0.6391 - bce_3: 1.0127 - acc_3: 0.5234 - bce_4: 0.9837 - acc_4: 0.5402\n",
      "\n",
      "tf.Tensor(0.5570971, shape=(), dtype=float32)\n",
      "tf.Tensor(0.033069342, shape=(), dtype=float32)\n",
      "tf.Tensor(0.041354228, shape=(), dtype=float32)\n",
      "  11/1306 [..............................] - ETA: 12:06 - loss_0: 0.9387 - cst_metric: 0.9424 - bce_: 0.9417 - acc_: 0.5757 - bce_0: 0.9758 - acc_0: 0.6034 - bce_1: 0.9567 - acc_1: 0.5717 - bce_2: 0.9208 - acc_2: 0.6379 - bce_3: 1.0118 - acc_3: 0.5250 - bce_4: 0.9805 - acc_4: 0.5418\n",
      "\n",
      "tf.Tensor(0.5365492, shape=(), dtype=float32)\n",
      "tf.Tensor(0.033105128, shape=(), dtype=float32)\n",
      "tf.Tensor(0.026903082, shape=(), dtype=float32)\n",
      "  12/1306 [..............................] - ETA: 12:05 - loss_0: 0.9285 - cst_metric: 0.9410 - bce_: 0.9406 - acc_: 0.5771 - bce_0: 0.9733 - acc_0: 0.6045 - bce_1: 0.9551 - acc_1: 0.5730 - bce_2: 0.9205 - acc_2: 0.6373 - bce_3: 1.0096 - acc_3: 0.5269 - bce_4: 0.9767 - acc_4: 0.5436\n",
      "\n",
      "tf.Tensor(0.53030694, shape=(), dtype=float32)\n",
      "tf.Tensor(0.029405162, shape=(), dtype=float32)\n",
      "tf.Tensor(0.027971793, shape=(), dtype=float32)\n",
      "  13/1306 [..............................] - ETA: 12:03 - loss_0: 0.9182 - cst_metric: 0.9391 - bce_: 0.9389 - acc_: 0.5787 - bce_0: 0.9701 - acc_0: 0.6056 - bce_1: 0.9529 - acc_1: 0.5745 - bce_2: 0.9196 - acc_2: 0.6370 - bce_3: 1.0067 - acc_3: 0.5290 - bce_4: 0.9724 - acc_4: 0.5454\n",
      "\n",
      "tf.Tensor(0.7132248, shape=(), dtype=float32)\n",
      "tf.Tensor(0.093896866, shape=(), dtype=float32)\n",
      "tf.Tensor(0.033720847, shape=(), dtype=float32)\n",
      "  14/1306 [..............................] - ETA: 12:01 - loss_0: 0.9089 - cst_metric: 0.9367 - bce_: 0.9367 - acc_: 0.5804 - bce_0: 0.9666 - acc_0: 0.6069 - bce_1: 0.9504 - acc_1: 0.5762 - bce_2: 0.9183 - acc_2: 0.6371 - bce_3: 1.0034 - acc_3: 0.5313 - bce_4: 0.9679 - acc_4: 0.5472\n",
      "\n",
      "tf.Tensor(0.6276043, shape=(), dtype=float32)\n",
      "tf.Tensor(0.010452996, shape=(), dtype=float32)\n",
      "tf.Tensor(0.022956107, shape=(), dtype=float32)\n",
      "  15/1306 [..............................] - ETA: 12:00 - loss_0: 0.9001 - cst_metric: 0.9341 - bce_: 0.9343 - acc_: 0.5821 - bce_0: 0.9629 - acc_0: 0.6081 - bce_1: 0.9475 - acc_1: 0.5778 - bce_2: 0.9168 - acc_2: 0.6373 - bce_3: 1.0000 - acc_3: 0.5336 - bce_4: 0.9632 - acc_4: 0.5490\n",
      "\n",
      "tf.Tensor(0.50231355, shape=(), dtype=float32)\n",
      "tf.Tensor(0.026101274, shape=(), dtype=float32)\n",
      "tf.Tensor(0.035204507, shape=(), dtype=float32)\n",
      "  16/1306 [..............................] - ETA: 12:08 - loss_0: 0.8914 - cst_metric: 0.9312 - bce_: 0.9316 - acc_: 0.5838 - bce_0: 0.9591 - acc_0: 0.6092 - bce_1: 0.9445 - acc_1: 0.5794 - bce_2: 0.9150 - acc_2: 0.6376 - bce_3: 0.9963 - acc_3: 0.5359 - bce_4: 0.9584 - acc_4: 0.5507\n",
      "\n",
      "tf.Tensor(0.5904372, shape=(), dtype=float32)\n",
      "tf.Tensor(0.012378665, shape=(), dtype=float32)\n",
      "tf.Tensor(0.02355849, shape=(), dtype=float32)\n",
      "  17/1306 [..............................] - ETA: 12:08 - loss_0: 0.8831 - cst_metric: 0.9281 - bce_: 0.9288 - acc_: 0.5854 - bce_0: 0.9552 - acc_0: 0.6104 - bce_1: 0.9413 - acc_1: 0.5810 - bce_2: 0.9131 - acc_2: 0.6380 - bce_3: 0.9926 - acc_3: 0.5381 - bce_4: 0.9536 - acc_4: 0.5524\n",
      "\n",
      "tf.Tensor(0.5278195, shape=(), dtype=float32)\n",
      "tf.Tensor(0.28948614, shape=(), dtype=float32)\n",
      "tf.Tensor(0.23100087, shape=(), dtype=float32)\n",
      "  18/1306 [..............................] - ETA: 12:07 - loss_0: 0.8750 - cst_metric: 0.9249 - bce_: 0.9258 - acc_: 0.5870 - bce_0: 0.9512 - acc_0: 0.6115 - bce_1: 0.9379 - acc_1: 0.5826 - bce_2: 0.9109 - acc_2: 0.6384 - bce_3: 0.9888 - acc_3: 0.5403 - bce_4: 0.9488 - acc_4: 0.5540\n",
      "\n",
      "tf.Tensor(0.38048464, shape=(), dtype=float32)\n",
      "tf.Tensor(-0.06273672, shape=(), dtype=float32)\n",
      "tf.Tensor(0.07133292, shape=(), dtype=float32)\n",
      "  19/1306 [..............................] - ETA: 12:05 - loss_0: 0.8668 - cst_metric: 0.9216 - bce_: 0.9227 - acc_: 0.5885 - bce_0: 0.9472 - acc_0: 0.6126 - bce_1: 0.9345 - acc_1: 0.5842 - bce_2: 0.9087 - acc_2: 0.6389 - bce_3: 0.9849 - acc_3: 0.5425 - bce_4: 0.9440 - acc_4: 0.5555\n",
      "\n",
      "tf.Tensor(0.43939015, shape=(), dtype=float32)\n",
      "tf.Tensor(0.02069333, shape=(), dtype=float32)\n",
      "tf.Tensor(0.02973086, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  20/1306 [..............................] - ETA: 12:05 - loss_0: 0.8588 - cst_metric: 0.9182 - bce_: 0.9195 - acc_: 0.5900 - bce_0: 0.9432 - acc_0: 0.6137 - bce_1: 0.9310 - acc_1: 0.5857 - bce_2: 0.9063 - acc_2: 0.6395 - bce_3: 0.9809 - acc_3: 0.5446 - bce_4: 0.9393 - acc_4: 0.5571\n",
      "\n",
      "tf.Tensor(0.40442628, shape=(), dtype=float32)\n",
      "tf.Tensor(0.27272242, shape=(), dtype=float32)\n",
      "tf.Tensor(0.26045075, shape=(), dtype=float32)\n",
      "  21/1306 [..............................] - ETA: 12:08 - loss_0: 0.8508 - cst_metric: 0.9148 - bce_: 0.9162 - acc_: 0.5916 - bce_0: 0.9392 - acc_0: 0.6148 - bce_1: 0.9275 - acc_1: 0.5873 - bce_2: 0.9038 - acc_2: 0.6401 - bce_3: 0.9769 - acc_3: 0.5467 - bce_4: 0.9346 - acc_4: 0.5586\n",
      "\n",
      "tf.Tensor(0.29397756, shape=(), dtype=float32)\n",
      "tf.Tensor(0.07124258, shape=(), dtype=float32)\n",
      "tf.Tensor(0.1094065, shape=(), dtype=float32)\n",
      "  22/1306 [..............................] - ETA: 12:08 - loss_0: 0.8427 - cst_metric: 0.9113 - bce_: 0.9129 - acc_: 0.5931 - bce_0: 0.9352 - acc_0: 0.6160 - bce_1: 0.9238 - acc_1: 0.5889 - bce_2: 0.9012 - acc_2: 0.6408 - bce_3: 0.9729 - acc_3: 0.5488 - bce_4: 0.9300 - acc_4: 0.5601\n",
      "\n",
      "tf.Tensor(0.34744924, shape=(), dtype=float32)\n",
      "tf.Tensor(0.1351476, shape=(), dtype=float32)\n",
      "tf.Tensor(0.16730995, shape=(), dtype=float32)\n",
      "  23/1306 [..............................] - ETA: 12:08 - loss_0: 0.8347 - cst_metric: 0.9077 - bce_: 0.9095 - acc_: 0.5947 - bce_0: 0.9311 - acc_0: 0.6171 - bce_1: 0.9202 - acc_1: 0.5905 - bce_2: 0.8985 - acc_2: 0.6416 - bce_3: 0.9688 - acc_3: 0.5509 - bce_4: 0.9254 - acc_4: 0.5617\n",
      "\n",
      "tf.Tensor(0.2139028, shape=(), dtype=float32)\n",
      "tf.Tensor(0.03767883, shape=(), dtype=float32)\n",
      "tf.Tensor(0.11837578, shape=(), dtype=float32)\n",
      "  24/1306 [..............................] - ETA: 12:06 - loss_0: 0.8266 - cst_metric: 0.9042 - bce_: 0.9060 - acc_: 0.5963 - bce_0: 0.9271 - acc_0: 0.6183 - bce_1: 0.9165 - acc_1: 0.5922 - bce_2: 0.8957 - acc_2: 0.6424 - bce_3: 0.9648 - acc_3: 0.5530 - bce_4: 0.9209 - acc_4: 0.5632\n",
      "\n",
      "tf.Tensor(0.34980655, shape=(), dtype=float32)\n",
      "tf.Tensor(0.11959651, shape=(), dtype=float32)\n",
      "tf.Tensor(0.116008006, shape=(), dtype=float32)\n",
      "  25/1306 [..............................] - ETA: 12:05 - loss_0: 0.8186 - cst_metric: 0.9005 - bce_: 0.9025 - acc_: 0.5979 - bce_0: 0.9230 - acc_0: 0.6196 - bce_1: 0.9128 - acc_1: 0.5938 - bce_2: 0.8928 - acc_2: 0.6433 - bce_3: 0.9607 - acc_3: 0.5550 - bce_4: 0.9164 - acc_4: 0.5648\n",
      "\n",
      "tf.Tensor(0.39184475, shape=(), dtype=float32)\n",
      "tf.Tensor(0.16650906, shape=(), dtype=float32)\n",
      "tf.Tensor(0.21997082, shape=(), dtype=float32)\n",
      "  26/1306 [..............................] - ETA: 12:03 - loss_0: 0.8110 - cst_metric: 0.8969 - bce_: 0.8990 - acc_: 0.5995 - bce_0: 0.9190 - acc_0: 0.6208 - bce_1: 0.9090 - acc_1: 0.5955 - bce_2: 0.8899 - acc_2: 0.6442 - bce_3: 0.9566 - acc_3: 0.5570 - bce_4: 0.9119 - acc_4: 0.5663\n",
      "\n",
      "tf.Tensor(0.49243668, shape=(), dtype=float32)\n",
      "tf.Tensor(0.3592273, shape=(), dtype=float32)\n",
      "tf.Tensor(0.32034504, shape=(), dtype=float32)\n",
      "  27/1306 [..............................] - ETA: 12:05 - loss_0: 0.8037 - cst_metric: 0.8932 - bce_: 0.8955 - acc_: 0.6011 - bce_0: 0.9150 - acc_0: 0.6220 - bce_1: 0.9053 - acc_1: 0.5972 - bce_2: 0.8869 - acc_2: 0.6452 - bce_3: 0.9526 - acc_3: 0.5590 - bce_4: 0.9076 - acc_4: 0.5678\n",
      "\n",
      "tf.Tensor(0.363381, shape=(), dtype=float32)\n",
      "tf.Tensor(-0.0034967966, shape=(), dtype=float32)\n",
      "tf.Tensor(0.115627825, shape=(), dtype=float32)\n",
      "  28/1306 [..............................] - ETA: 12:04 - loss_0: 0.7966 - cst_metric: 0.8896 - bce_: 0.8919 - acc_: 0.6027 - bce_0: 0.9110 - acc_0: 0.6233 - bce_1: 0.9016 - acc_1: 0.5988 - bce_2: 0.8839 - acc_2: 0.6462 - bce_3: 0.9486 - acc_3: 0.5610 - bce_4: 0.9033 - acc_4: 0.5694\n",
      "\n",
      "tf.Tensor(1.2425169, shape=(), dtype=float32)\n",
      "tf.Tensor(0.023981877, shape=(), dtype=float32)\n",
      "tf.Tensor(0.13894665, shape=(), dtype=float32)\n",
      "  29/1306 [..............................] - ETA: 12:02 - loss_0: 0.7908 - cst_metric: 0.8860 - bce_: 0.8885 - acc_: 0.6043 - bce_0: 0.9071 - acc_0: 0.6246 - bce_1: 0.8979 - acc_1: 0.6005 - bce_2: 0.8810 - acc_2: 0.6472 - bce_3: 0.9446 - acc_3: 0.5630 - bce_4: 0.8991 - acc_4: 0.5709\n",
      "\n",
      "tf.Tensor(0.31640312, shape=(), dtype=float32)\n",
      "tf.Tensor(0.31304073, shape=(), dtype=float32)\n",
      "tf.Tensor(0.20947492, shape=(), dtype=float32)\n",
      "  30/1306 [..............................] - ETA: 12:01 - loss_0: 0.7850 - cst_metric: 0.8824 - bce_: 0.8850 - acc_: 0.6059 - bce_0: 0.9033 - acc_0: 0.6258 - bce_1: 0.8942 - acc_1: 0.6022 - bce_2: 0.8780 - acc_2: 0.6482 - bce_3: 0.9407 - acc_3: 0.5650 - bce_4: 0.8950 - acc_4: 0.5724\n",
      "\n",
      "tf.Tensor(0.405588, shape=(), dtype=float32)\n",
      "tf.Tensor(0.15041253, shape=(), dtype=float32)\n",
      "tf.Tensor(0.16526856, shape=(), dtype=float32)\n",
      "  31/1306 [..............................] - ETA: 12:00 - loss_0: 0.7794 - cst_metric: 0.8789 - bce_: 0.8816 - acc_: 0.6075 - bce_0: 0.8996 - acc_0: 0.6271 - bce_1: 0.8907 - acc_1: 0.6038 - bce_2: 0.8751 - acc_2: 0.6493 - bce_3: 0.9369 - acc_3: 0.5669 - bce_4: 0.8910 - acc_4: 0.5739\n",
      "\n",
      "tf.Tensor(0.32283276, shape=(), dtype=float32)\n",
      "tf.Tensor(0.19755808, shape=(), dtype=float32)\n",
      "tf.Tensor(0.22002542, shape=(), dtype=float32)\n",
      "  32/1306 [..............................] - ETA: 12:02 - loss_0: 0.7738 - cst_metric: 0.8754 - bce_: 0.8782 - acc_: 0.6091 - bce_0: 0.8959 - acc_0: 0.6284 - bce_1: 0.8871 - acc_1: 0.6055 - bce_2: 0.8722 - acc_2: 0.6504 - bce_3: 0.9331 - acc_3: 0.5689 - bce_4: 0.8871 - acc_4: 0.5755\n",
      "\n",
      "tf.Tensor(0.36372513, shape=(), dtype=float32)\n",
      "tf.Tensor(0.19816104, shape=(), dtype=float32)\n",
      "tf.Tensor(0.19282678, shape=(), dtype=float32)\n",
      "  33/1306 [..............................] - ETA: 12:01 - loss_0: 0.7684 - cst_metric: 0.8719 - bce_: 0.8749 - acc_: 0.6107 - bce_0: 0.8923 - acc_0: 0.6297 - bce_1: 0.8836 - acc_1: 0.6071 - bce_2: 0.8693 - acc_2: 0.6514 - bce_3: 0.9294 - acc_3: 0.5708 - bce_4: 0.8833 - acc_4: 0.5770\n",
      "\n",
      "tf.Tensor(1.1526638, shape=(), dtype=float32)\n",
      "tf.Tensor(0.432702, shape=(), dtype=float32)\n",
      "tf.Tensor(0.50705266, shape=(), dtype=float32)\n",
      "  34/1306 [..............................] - ETA: 12:00 - loss_0: 0.7638 - cst_metric: 0.8685 - bce_: 0.8716 - acc_: 0.6123 - bce_0: 0.8887 - acc_0: 0.6309 - bce_1: 0.8802 - acc_1: 0.6088 - bce_2: 0.8664 - acc_2: 0.6525 - bce_3: 0.9257 - acc_3: 0.5727 - bce_4: 0.8795 - acc_4: 0.5785\n",
      "\n",
      "tf.Tensor(0.06338798, shape=(), dtype=float32)\n",
      "tf.Tensor(-0.05170858, shape=(), dtype=float32)\n",
      "tf.Tensor(0.23905712, shape=(), dtype=float32)\n",
      "  35/1306 [..............................] - ETA: 11:58 - loss_0: 0.7590 - cst_metric: 0.8652 - bce_: 0.8684 - acc_: 0.6139 - bce_0: 0.8852 - acc_0: 0.6322 - bce_1: 0.8768 - acc_1: 0.6104 - bce_2: 0.8636 - acc_2: 0.6536 - bce_3: 0.9221 - acc_3: 0.5746 - bce_4: 0.8759 - acc_4: 0.5799\n",
      "\n",
      "tf.Tensor(0.43524113, shape=(), dtype=float32)\n",
      "tf.Tensor(0.3449086, shape=(), dtype=float32)\n",
      "tf.Tensor(0.4431327, shape=(), dtype=float32)\n",
      "  36/1306 [..............................] - ETA: 11:57 - loss_0: 0.7543 - cst_metric: 0.8619 - bce_: 0.8652 - acc_: 0.6154 - bce_0: 0.8818 - acc_0: 0.6335 - bce_1: 0.8735 - acc_1: 0.6120 - bce_2: 0.8608 - acc_2: 0.6547 - bce_3: 0.9186 - acc_3: 0.5764 - bce_4: 0.8723 - acc_4: 0.5814\n",
      "\n",
      "tf.Tensor(0.3568151, shape=(), dtype=float32)\n",
      "tf.Tensor(0.24585538, shape=(), dtype=float32)\n",
      "tf.Tensor(0.32632938, shape=(), dtype=float32)\n",
      "  37/1306 [..............................] - ETA: 11:58 - loss_0: 0.7497 - cst_metric: 0.8587 - bce_: 0.8621 - acc_: 0.6169 - bce_0: 0.8784 - acc_0: 0.6347 - bce_1: 0.8703 - acc_1: 0.6136 - bce_2: 0.8581 - acc_2: 0.6558 - bce_3: 0.9151 - acc_3: 0.5782 - bce_4: 0.8688 - acc_4: 0.5829\n",
      "\n",
      "tf.Tensor(0.19529432, shape=(), dtype=float32)\n",
      "tf.Tensor(0.15970685, shape=(), dtype=float32)\n",
      "tf.Tensor(0.5015976, shape=(), dtype=float32)\n",
      "  38/1306 [..............................] - ETA: 11:58 - loss_0: 0.7451 - cst_metric: 0.8555 - bce_: 0.8590 - acc_: 0.6185 - bce_0: 0.8751 - acc_0: 0.6360 - bce_1: 0.8670 - acc_1: 0.6151 - bce_2: 0.8554 - acc_2: 0.6568 - bce_3: 0.9117 - acc_3: 0.5800 - bce_4: 0.8654 - acc_4: 0.5843\n",
      "\n",
      "tf.Tensor(0.5949025, shape=(), dtype=float32)\n",
      "tf.Tensor(0.13306317, shape=(), dtype=float32)\n",
      "tf.Tensor(0.35448655, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  39/1306 [..............................] - ETA: 11:57 - loss_0: 0.7407 - cst_metric: 0.8523 - bce_: 0.8560 - acc_: 0.6200 - bce_0: 0.8719 - acc_0: 0.6372 - bce_1: 0.8639 - acc_1: 0.6167 - bce_2: 0.8527 - acc_2: 0.6579 - bce_3: 0.9083 - acc_3: 0.5818 - bce_4: 0.8621 - acc_4: 0.5857\n",
      "\n",
      "tf.Tensor(0.32691413, shape=(), dtype=float32)\n",
      "tf.Tensor(0.1815521, shape=(), dtype=float32)\n",
      "tf.Tensor(0.23720583, shape=(), dtype=float32)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~tmp/ipykernel_8556/790524998.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcst_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_eagerly\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m cst_model.fit(\n\u001b[1;32m      6\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mt_flow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~usr/local/lib/python3.8/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1440\u001b[0m       \u001b[0;31m# If eval data_handler exists, delete it after all epochs are done.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_eval_data_handler'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1442\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_eval_data_handler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1443\u001b[0m       \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1444\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~usr/local/lib/python3.8/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m   1019\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1020\u001b[0m         \u001b[0;34m\"\"\"Runs a training execution with a single step.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mstep_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~usr/local/lib/python3.8/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(model, iterator)\u001b[0m\n\u001b[1;32m   1006\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1007\u001b[0m         run_step = tf.function(\n\u001b[1;32m   1008\u001b[0m             run_step, jit_compile=True, experimental_relax_shapes=True)\n\u001b[1;32m   1009\u001b[0m       \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1010\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1011\u001b[0m       outputs = reduce_per_replica(\n\u001b[1;32m   1012\u001b[0m           outputs, self.distribute_strategy, reduction='first')\n\u001b[1;32m   1013\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1308\u001b[0m       \u001b[0;31m# tf.distribute supports Eager functions, so AutoGraph should not be\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m       \u001b[0;31m# applied when the caller is also in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1310\u001b[0m       fn = autograph.tf_convert(\n\u001b[1;32m   1311\u001b[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[0;32m-> 1312\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extended\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   2884\u001b[0m     \u001b[0m_require_cross_replica_or_default_context_extended\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2885\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2886\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2887\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2888\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3687\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3688\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mReplicaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplica_id_in_sync_group\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3689\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    593\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mControlStatusCtx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUNSPECIFIED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 595\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~usr/local/lib/python3.8/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    999\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mrun_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1000\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1001\u001b[0m         \u001b[0;31m# Ensure counter is updated only if `train_step` succeeds.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1002\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_minimum_control_deps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1003\u001b[0m           \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~main_dir/felipe/projects/processor_apps/pkgs/CST/cst/cst_model.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;31m# y_pred, y_dists, loss, tape = self._forward_pass(x, y, training=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0mtrainable_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m         \u001b[0mgradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;31m# self.st_loss_tracker.update_state(loss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1077\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0moutput_gradients\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1078\u001b[0m       output_gradients = [None if x is None else ops.convert_to_tensor(x)\n\u001b[1;32m   1079\u001b[0m                           for x in nest.flatten(output_gradients)]\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1081\u001b[0;31m     flat_grad = imperative_grad.imperative_grad(\n\u001b[0m\u001b[1;32m   1082\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m         \u001b[0mflat_targets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0mflat_sources\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     63\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     raise ValueError(\n\u001b[1;32m     65\u001b[0m         \"Unknown value for unconnected_gradients: %r\" % unconnected_gradients)\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m   return pywrap_tfe.TFE_Py_TapeGradient(\n\u001b[0m\u001b[1;32m     68\u001b[0m       \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m       \u001b[0msources\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0mgradient_name_scope\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"gradient_tape/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mforward_pass_name_scope\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m       \u001b[0mgradient_name_scope\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mforward_pass_name_scope\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient_name_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/nn_grad.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m    573\u001b[0m   \u001b[0;31m# to use the nn_ops functions, we would have to convert `padding` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m   \u001b[0;31m# `explicit_paddings` into a single `padding` parameter, increasing overhead\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m   \u001b[0;31m# in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m   return [\n\u001b[0;32m--> 577\u001b[0;31m       gen_nn_ops.conv2d_backprop_input(\n\u001b[0m\u001b[1;32m    578\u001b[0m           \u001b[0mshape_0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m           \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m           \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(input_sizes, filter, out_backprop, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)\u001b[0m\n\u001b[1;32m   1245\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1246\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1247\u001b[0m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1248\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1249\u001b[0;31m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1250\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1251\u001b[0m       return conv2d_backprop_input_eager_fallback(\n\u001b[1;32m   1252\u001b[0m           \u001b[0minput_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_backprop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "cst_model.run_eagerly = True\n",
    "\n",
    "cst_model.fit(\n",
    "    x=t_flow,\n",
    "    validation_data=v_flow,\n",
    "    epochs=epochs,\n",
    "    class_weight=bm.get_class_weights(t_flow.classes)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337d8356",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6a595f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4e13a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
